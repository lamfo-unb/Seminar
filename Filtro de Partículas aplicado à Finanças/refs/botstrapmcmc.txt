Bootstrapping is a statistical technique used to attain independence for a predictive model. In bootstrapping the data have already been collected. In Monte Carlo techniques usually a distribution is assumed in order for the big data generated by a variable or a series of variables to be interpreted with a view of quantifying uncertainties. Monte Carlo techniques also help in sensitivity analysis (Sensitivity analysis - Wikipedia).

https://www.quora.com/What-is-the-difference-between-boostrap-and-Monte-Carlo


bootstrapping is resampling from known samples, monte carlo is trying to generate data depend on some parameters.
we have samples, for example, 3, 2, 1, 5, 6, but sample size is too small, so we resample from this sample set for 10000 times, then the new sample set is more robust to represent something, this called bootstrapping.
so boostrapping is based on unknown distribution, and Monte Carlo based on known distribution.
The tie between the bootstrap and Monte Carlo simulation of a statistic is obvious: Both are based on repetitive sampling and then direct examination of the results. A big difference between the methods, however, is that bootstrapping uses the original, initial sample as the population from which to resample, whereas Monte Carlo simulation is based on setting up a data generation process (with known values of the parameters). Where Monte Carlo is used to test drive estimators, bootstrap methods can be used to estimate the variability of a statistic and the shape of its sampling distribution.

https://jingqiumao.wordpress.com/2008/07/21/difference-between-monte-carlo-and-bootstrapping/


DOC


http://faculty.etsu.edu/trainor/FNCE%203300/Var1.htm